{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Instructions:\n",
    "1. **Restart the kernel** (in the menubar, select Runtime$\\rightarrow$Restart runtime)\n",
    "2. **Run all cells** (in the menubar, select Runtime$\\rightarrow$Run All).\n",
    "3. **Download the notebook** (in the menubar, select File$\\rightarrow$Download .ipynb)\n",
    "4. **Add the downloaded notebook (.ipynb file) to the submission zip**.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"**WRITE YOUR ANSWER IN THIS CELL**\", and that no tests fail.  \n",
    "Write the IDs of all group members in the cell below. Leave any surplus IDs as `\"\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID1 = \"301687901\"\n",
    "ID2 = \"305640393\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5493400e8b7f9a8e2cde874866d4fa7f",
     "grade": false,
     "grade_id": "cell-3a1bca1dbb7d0069",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "![shakespeare](https://i.imgur.com/81YZuel.jpg)\n",
    "\n",
    "# Generating Shakespeare Using a Character-level Language Model\n",
    "\n",
    "### From Words to Characters\n",
    "In the previous two sections we dealt with word-level language models. But looking again at section 2, there is nothing that constraints us to using _words_ as the basic elemnents in our model. The model we analyzed in section 2 could just as well be character-based - just replace \"word\" with \"character\", and you are good to go. In this notebook we will train a small character-based language model that will help us generate Shakespearean-like (emphasis on the _like_...) texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9af7a343d0e3524c3fd846d987d766a8",
     "grade": false,
     "grade_id": "cell-7301754e4d655d01",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 3.a\n",
    "Can you think of an advantage a character-based language model could have over a word-based language model? _(You might find question 2.c useful)_. And what about the other way around: can you think of an advantage a word-based language model could have over a character-based language model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb742db028fffc9c69d14202fc1e24bd",
     "grade": true,
     "grade_id": "cell-e19646c939692ee9",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**WRITE YOUR ANSWER IN THIS CELL**\n",
    "From question 2.c. we can see that the operations we need to perform in both forward and backward dependent on |V|, which can be pretty big in Word-based model. However, in Character-based model |V| is limitted and not so big.\n",
    "On the other hand, in case of Word-based model, the model can learn and perform better result because the generalization is better in Word-based case than Character-based."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d46a8dfd340b8f68e51a041307f7d7d3",
     "grade": false,
     "grade_id": "cell-ebc0d8ae3061c0fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Using PyTorch\n",
    "\n",
    "We'll build our language model using PyTorch. PyTorch is a [very popular](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/) open-source machine learning (and deep learning) framework developed by Facebook. In short:\n",
    "\n",
    "> Pytorch is a Python-based scientific computing package targeted at two sets of audiences:\n",
    "* A replacement for NumPy to use the power of GPUs\n",
    "* A deep learning research platform that provides maximum flexibility and speed\n",
    "\n",
    "To get familiar with PyTorch, check out this [quick tutorial](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html). In addition, another imporant difference from numpy is that PyTorch can automatically calculate the gradients needed for backpropagation, as explained [here](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02af8a21a2e8fae58d84f915de5b016d",
     "grade": false,
     "grade_id": "cell-aa2773db1bef7014",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Preparing the Data\n",
    "\n",
    "Our dataset is a plain text file. For simplicity, we turn any potential unicode characters into plain ASCII by using the `unidecode` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef0359e8c08b2057771c115150011e7e",
     "grade": false,
     "grade_id": "cell-cce75419c097f3fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in our dataset: 1115394\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "import re\n",
    "\n",
    "import unidecode\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)  # our vocabulary size (|V| from the handout)\n",
    "\n",
    "dataset_as_string = unidecode.unidecode(open('data/shakespeare.txt').read())\n",
    "n_chars_in_dataset = len(dataset_as_string)\n",
    "print(f'Total number of characters in our dataset: {n_chars_in_dataset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06dd2ac91a6296206475c7e330e53e3d",
     "grade": false,
     "grade_id": "cell-d795f907dd7922f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To make inputs out of this big string of text, we will split it into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61947ad22fb7f16eba246d47ab8cae22",
     "grade": false,
     "grade_id": "cell-379f229536dae19b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sir, my lord,\n",
      "I could do this, and that with no rash potion,\n",
      "But with a lingering dram that should not work\n",
      "Maliciously like poison: but I cannot\n",
      "Believe this crack to be in my dread mistress,\n",
      "So sovereignly being honourable.\n",
      "I have loved thee,--\n",
      "\n",
      "LEONTES:\n",
      "Make that thy question, and go rot!\n",
      "Dost think I am so muddy, so unsettled,\n",
      "To appoint myself in this vexation, sully\n",
      "The purity and whiteness \n"
     ]
    }
   ],
   "source": [
    "chunk_len = 400\n",
    "\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, n_chars_in_dataset - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return dataset_as_string[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba5d4900ff254fa335fe935962878c8d",
     "grade": false,
     "grade_id": "cell-fcbb2d73f4e442fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Building Our Model\n",
    "\n",
    "Our model consists of three main components:\n",
    "\n",
    "1. [**Embedding**](https://pytorch.org/docs/stable/nn.html#embedding). A mapping between characters and their learned representations (\"word vectors\") \\[correspoding to ${\\boldsymbol L}$ in terms of the handout\\]\n",
    "2. [**GRU**](https://pytorch.org/docs/stable/nn.html#gru). \\[correspoding to the computation of ${\\boldsymbol h}^{(t)}$ in terms of the handout\\]\n",
    "3. **Output Layer**. A feed-forward neural network that transforms a hidden state at a timestep into a probability distribution of the next character. \\[correspoding to the computation of $\\hat{\\boldsymbol y}^{(t)}$ in terms of the handout\\] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.b\n",
    "Complete the implementation of the `forward` method of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9ad1239fcd5aec23f439249397895ec",
     "grade": false,
     "grade_id": "cell-1640492438386e87",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class OurModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(OurModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)  # In the terms of the handout, here d = D_h\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input_, hidden):\n",
    "        # General instructions:\n",
    "        # Pass the embedded input through the GRU and use the output layer to get the next character distribution.\n",
    "        # return that distribution and the next hidden state.\n",
    "        # You may need to play around with the dimensions a bit until you get it right. Dimension-induced frustration is good for you!\n",
    "        # -------------------------\n",
    "        # YOUR CODE HERE\n",
    "        if len(input_.shape) == 0:\n",
    "            input_ = input_.unsqueeze(0)\n",
    "        emb = self.embedding(input_)\n",
    "        emb = emb.unsqueeze(0)\n",
    "        out, hidden = self.gru(emb, hidden)\n",
    "        output = self.output_layer(out)\n",
    "        output = output.squeeze(0)\n",
    "        # -------------------------\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.num_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da793a49917dc4882e7e70f04d07a777",
     "grade": false,
     "grade_id": "cell-b9299fddeb082b4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Creating the Training Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6eaeb80c370b32f26eda2ac1be57444",
     "grade": false,
     "grade_id": "cell-83bf9e1b0374206c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Each chunk will be turned into a tensor by looping through the characters of the string and looking up the index of each character in `all_characters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc87bca342db2fde1b3957f48bcfe857",
     "grade": false,
     "grade_id": "cell-5360afdd0b03b1f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 11, 12, 39, 40, 41])\n"
     ]
    }
   ],
   "source": [
    "# Turn a string into list of longs\n",
    "def chars_to_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "print(chars_to_tensor('abcDEF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32c02aa64cee9046c2917487ac982de0",
     "grade": false,
     "grade_id": "cell-6e7b3d9e8c9396bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Each training example for our model will be created from a chunk randomly extracted from our shakespeare dataset. For example, if we set our chunk size to be 28, then a randomly extracted chunk could be $\\texttt{As deep as that, though true}$. Each training example is of a form $(\\textbf{x},\\textbf{y})$ where $\\textbf{x}$ is all the charecters of the chunk *except the last* and $\\textbf{y}$ is all the charecters of the chunk *except the first*. For example, given the chunk above, $\\textbf{x}=\\texttt{As deep as that, though tru}$ and $\\textbf{y}=\\texttt{s deep as that, though true}$. At timestep i our input is $\\textbf{x}^{(i)}$ and the gold label our model will try to predict is $\\textbf{y}^{(i)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f159d648c0ab9ffbdc096aeac6905a57",
     "grade": false,
     "grade_id": "cell-d3539c5f1d96a188",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def random_training_example():    \n",
    "    chunk = random_chunk()\n",
    "    inp = chars_to_tensor(chunk[:-1])\n",
    "    target = chars_to_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18a6bf800d9bc590739b15ba01dda408",
     "grade": false,
     "grade_id": "cell-16d13f3b273395ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Evaluating\n",
    "\n",
    "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a47c721a818979b886f119401206e756",
     "grade": false,
     "grade_id": "cell-44ab27a8fee696ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = model.init_hidden()\n",
    "    prime_input = chars_to_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = model(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = model(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist =  F.softmax(output / temperature, dim=-1)\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = chars_to_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fffa10554299eaae14cc007fea3935a",
     "grade": false,
     "grade_id": "cell-1d3fd015fe8f64d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a98218b35f47137eeba1ba1aead0700",
     "grade": false,
     "grade_id": "cell-a209b293a8850a57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The main training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb3bfcd4d49b2f2672447d8c65b6cb05",
     "grade": false,
     "grade_id": "cell-e246cbd9689e1a6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = model.init_hidden()\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = model(inp[c], hidden)\n",
    "        loss += criterion(output, target[c].view(-1))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item() / chunk_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfb863e279db4b170c35d8d0c7a37a1f",
     "grade": false,
     "grade_id": "cell-05ce9b9275e0d1cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A helper to print the amount of time passed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16d7b53f211a6a1bef71c1dd2d1271cf",
     "grade": false,
     "grade_id": "cell-cb78afef7022f9a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return f'{m}m {math.floor(s)}s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b368f1767ddd0eddca44249fa47ed32",
     "grade": true,
     "grade_id": "cell-98f46bec0b8c87cc",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98abd7dd7805753c2e7b635f1265cb73",
     "grade": false,
     "grade_id": "cell-baf25642209867dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Define the training parameters, instantiate the model, and start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7392249521c153ef4d7713eecb8204a",
     "grade": false,
     "grade_id": "cell-4900f92ae503be69",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[time elapsed: 0m 35s  ;  iterations: 100 (5.0%)  ;  loss: 2.198]\n",
      "Why and oull bin.\n",
      "\n",
      "CERICQUS:\n",
      "Ou I the hapime thav venfesen te hert merea pall und pean ban sine he upeas mer has blel he path\n",
      "hutich fat lod ared the ey,\n",
      "He thath a het had me\n",
      "hinis hipees ing you feand \n",
      "\n",
      "[time elapsed: 1m 12s  ;  iterations: 200 (10.0%)  ;  loss: 2.163]\n",
      "Whe homade how thou losst in that thou to the ome thou wo rane, bentue to my the of weit, comefor me eath ane'd air, art the leart.\n",
      "\n",
      "CUCER:\n",
      "Wist brave ot wait tay my to manten, go his to molfor boder\n",
      "jo \n",
      "\n",
      "[time elapsed: 1m 54s  ;  iterations: 300 (15.0%)  ;  loss: 1.995]\n",
      "Whave lice wo love that the to stragey\n",
      "And was be now, ing were his be the theee and the the madeds as moins the thins and as of your\n",
      "By love, great, there\n",
      "Will the prough mepus whis aoke the will notin \n",
      "\n",
      "[time elapsed: 2m 33s  ;  iterations: 400 (20.0%)  ;  loss: 2.141]\n",
      "Whe him that with be, all wea her herse you harry be to by hing hime fathen make is in old!\n",
      "How hear, not ontly but her sare, my lond manes:\n",
      "The she son a he sweld to like we be love,\n",
      "In's cother the no \n",
      "\n",
      "[time elapsed: 3m 9s  ;  iterations: 500 (25.0%)  ;  loss: 1.872]\n",
      "Whime to dike mine to comman, my to the word me?\n",
      "\n",
      "KING RICINCENTIO:\n",
      "He camp seevels thou.\n",
      "I have and in 'tand the of geve dauth!\n",
      "Frught words under his lover me and fecunce now.\n",
      "\n",
      "Catruak vears.\n",
      "\n",
      "PERUMIO \n",
      "\n",
      "[time elapsed: 3m 44s  ;  iterations: 600 (30.0%)  ;  loss: 1.836]\n",
      "What have Kust ender for that pepervy soo?\n",
      "\n",
      "BLOUCESTER:\n",
      "A are no dead ouver should fail down:\n",
      "We home, this shoud the shalt:\n",
      "Tave it the truits upitized but oinks; shall suck\n",
      "Who that I was comend ball  \n",
      "\n",
      "[time elapsed: 4m 18s  ;  iterations: 700 (35.0%)  ;  loss: 1.755]\n",
      "Whe him are is and thy we shall soineed.\n",
      "\n",
      "BONY:\n",
      "No, call abour tity you deed.\n",
      "\n",
      "LUCETHUS:\n",
      "What yout do stagemon is of it hate of you for dimped\n",
      "ne coand be it all it utis in full in elords, yales if all  \n",
      "\n",
      "[time elapsed: 4m 53s  ;  iterations: 800 (40.0%)  ;  loss: 1.741]\n",
      "Whe heart his brothes to live fair of thee.\n",
      "\n",
      "ROMEO:\n",
      "That well buts your laine, him the the trease, not I all blow,\n",
      "That a cheed unty folss, have the good ment like of caagain\n",
      "I well thou presear and to  \n",
      "\n",
      "[time elapsed: 5m 28s  ;  iterations: 900 (45.0%)  ;  loss: 1.884]\n",
      "What and yourself or knoth to their not netruen.\n",
      "\n",
      "PETRUCHIO:\n",
      "Sure that Come, which hold dive dires,\n",
      "Ints in to dood, sorrow, will straighters,\n",
      "Why may deal heas sir, not he moysion,\n",
      "Whath the a atin cro \n",
      "\n",
      "[time elapsed: 6m 3s  ;  iterations: 1000 (50.0%)  ;  loss: 1.907]\n",
      "When:\n",
      "And cears, thou prome, that and sir?\n",
      "\n",
      "JORCABKIA:\n",
      "I have uriess the hear, the will in us so wa\n",
      "Gporst see, and the very to her as a reach\n",
      "Warwy'd for should le:' the firer'd-woire?\n",
      "\n",
      "LUCENIUS:\n",
      "And,  \n",
      "\n",
      "[time elapsed: 6m 38s  ;  iterations: 1100 (55.00000000000001%)  ;  loss: 1.726]\n",
      "Whathar!\n",
      "What come it, wilt; 'twating so, or ladrion, soo sin;\n",
      "Apon that to to stoo, by up ashal death seepers and on I ling your good like of thou proud,\n",
      "Why, ting our deavy old drace ris him tong your \n",
      "\n",
      "[time elapsed: 7m 13s  ;  iterations: 1200 (60.0%)  ;  loss: 1.664]\n",
      "Whar with thy man the comes\n",
      "A besttle, Byan, of wither.\n",
      "\n",
      "AUCHIO:\n",
      "When thing of yourself you may as thanged of your'd the strack\n",
      "That your the filled a blow one gother them we like a to fort six\n",
      "a fliene \n",
      "\n",
      "[time elapsed: 7m 48s  ;  iterations: 1300 (65.0%)  ;  loss: 1.54]\n",
      "Whim the sounds,\n",
      "Where see the in the sain I dauking are in\n",
      "Wan lais as though that and take us not her the fluty warry dols'\n",
      "But wheng shall so speeds agale took to the distrither.\n",
      "\n",
      "First Clifned.\n",
      "\n",
      "HER \n",
      "\n",
      "[time elapsed: 8m 23s  ;  iterations: 1400 (70.0%)  ;  loss: 2.127]\n",
      "WhUng been the, and that cencorrifench,\n",
      "And marry that to mading's wrong take, the poort, so with make,\n",
      "Gods hing and in resome, the gone,\n",
      "Were in sird unce poistain that concean,\n",
      "So, I can man, is in t \n",
      "\n",
      "[time elapsed: 8m 58s  ;  iterations: 1500 (75.0%)  ;  loss: 1.419]\n",
      "Wh: have with the\n",
      "Be marnow. What thabstitious.\n",
      "\n",
      "BAKINGA:\n",
      "But of Yourse.\n",
      "\n",
      "KING HENY:\n",
      "Ghow'd thy like the right our this to wad and day the die but the it not telcome in town,\n",
      "Walk, you, this king's Came \n",
      "\n",
      "[time elapsed: 9m 33s  ;  iterations: 1600 (80.0%)  ;  loss: 1.778]\n",
      "Wh, good and my spead, and blood!\n",
      "\n",
      "COLIONES:\n",
      "And suspain set you words mouth would shall how that feed\n",
      "Whoine you like of thie.\n",
      "\n",
      "SirX\n",
      "Cllay, I see come and all a but the\n",
      "come a rown songerous befor now  \n",
      "\n",
      "[time elapsed: 10m 7s  ;  iterations: 1700 (85.0%)  ;  loss: 1.607]\n",
      "Whar fiver\n",
      "Who do face for your he furbend\n",
      "Who so unit is the bursian to me\n",
      "Have you this of a sile the love\n",
      "Shall for sovander pears all us may with my fliced,\n",
      "With you every should servants, him you s \n",
      "\n",
      "[time elapsed: 10m 43s  ;  iterations: 1800 (90.0%)  ;  loss: 1.825]\n",
      "Whit him.\n",
      "\n",
      "PORTESNIUS:\n",
      "I'll by you blament loign intered.\n",
      "\n",
      "KING HERCHERY VI:\n",
      "Thor his? while the will him hived is therefore:\n",
      "And her postracion be that with they pretiner.\n",
      "\n",
      "HASTINA:\n",
      "Hiss poinery than y \n",
      "\n",
      "[time elapsed: 11m 18s  ;  iterations: 1900 (95.0%)  ;  loss: 1.656]\n",
      "Wher hold, sire: stay?\n",
      "\n",
      "Servats?\n",
      "\n",
      "LADY VI\n",
      "This losts ear of merter beserfore brand,\n",
      "Which horsed crosin of there will know these.\n",
      "To he deather, thou will there conse: dow?\n",
      "Weartiomed thou wings unlongs \n",
      "\n",
      "[time elapsed: 11m 57s  ;  iterations: 2000 (100.0%)  ;  loss: 1.484]\n",
      "Whergrus love of thems!\n",
      "\n",
      "Firs:\n",
      "So, wister the for conder the with sold.\n",
      "\n",
      "GLOUCESTER:\n",
      "Or spee, givy sided, where deeds, the litains,\n",
      "Of whom heeernt. I would slacompone.\n",
      "\n",
      "GLOUCESTER:\n",
      "What, and a here as  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 100  # (D_h from the handout)\n",
    "num_layers = 1\n",
    "lr = 0.005\n",
    "\n",
    "model = OurModel(n_characters, hidden_size, n_characters, num_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for iteration in range(1, n_iterations + 1):\n",
    "    loss = train(*random_training_example())       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if iteration % print_every == 0:\n",
    "        print(f'[time elapsed: {time_since(start)}  ;  iterations: {iteration} ({iteration / n_iterations * 100}%)  ;  loss: {loss:.4}]')\n",
    "        print(evaluate('Wh', 200), '\\n')  # generate text starting with 'Wh'\n",
    "\n",
    "    if iteration % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8584d3be75d90a5197e7133411e0021d",
     "grade": false,
     "grade_id": "cell-ff9d72dafefa0a23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training Loss\n",
    "\n",
    "Plotting the the losses that were computed during training can provide a further indication that the network was indeed learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77791204e14b67d3ad68d70695c479a6",
     "grade": false,
     "grade_id": "cell-f91bb597844b8f7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11efb28d0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel('# of iterations (divided by plot_every)')\n",
    "plt.ylabel('average loss')\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a376c5ed8b8f2dff9ea4731669bc8a49",
     "grade": false,
     "grade_id": "cell-dac1f386e2b526f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Evaluating at Different Temperatures\n",
    "Every time we use the `evaluate` function to generate the distribution of the next character, we don't just use softmax as usual, but we also divide by a `temperature`.  \n",
    "Let's examine the effect of changing the temperature when generating text using our trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The words:\n",
      "Which our so so the with the with the with the with the with the with the with the with the with the with the with the with the with the with the with the with the with the proud the with the with the with the with the with the with the with the with the with the with the with the with the with the proud the with the with the with the proud the with the with the with the with the with the\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Th', 400, temperature=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The the were for the deather:\n",
      "Which to this so with stnown with faith pition:\n",
      "I have for as the with that with me we so so he would.\n",
      "\n",
      "GLOUCESTER:\n",
      "And so so with the for your our to he with me deather:\n",
      "Where the so with siting to his lord.\n",
      "\n",
      "GLOUCESTER:\n",
      "And self me a king of the with me.\n",
      "\n",
      "GLOUCESTER:\n",
      "My so the with his stone he with we\n",
      "But a words to me a stright.\n",
      "\n",
      "GREMIO:\n",
      "What the which the lived the\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Th', 400, temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Th:\n",
      "I may, leds, bearled, hand,\n",
      "For his cheer the wond of we art desside\n",
      "Such signse thou by stend there it.\n",
      "\n",
      "BARGARD OF VINCENTIO:\n",
      "What were, you riked to suren mory Lord-\n",
      "GREMIUS:\n",
      "But the kings his preds do alark,\n",
      "And me confelve great aid yebary up so up is:\n",
      "Whouse inted, a but dranfer and the show is every\n",
      "Being to him his had we woo wither.\n",
      "\n",
      "AUTUS:\n",
      "What you have looks whereann'd is provines\n",
      "For\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Th', 400, temperature=0.8))  # the default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thee,\n",
      "And, speres at through to in like rust;\n",
      "And soublal fromin'd to our with spit thorman,\n",
      "And says right speak as and\n",
      "A go thir ye Lord yeavence,\n",
      "In't to pleath miss the bread,\n",
      "The carrsinss he his light, vanged sined: who the hath you;\n",
      "Thou bovows in will ome Corood.\n",
      "I hie true to and our hove, us;\n",
      "A upon Oce are nurding prentued, and with our which,\n",
      "Edy whill our now.\n",
      "\n",
      "DO RIVESe\n",
      "But of, to to n\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Th', 400, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thom' for3R\n",
      "Ze'ncelages.' vind houghtsets: he die, witunss elow?\n",
      "gence. with' thy roschdrent tilaniraf; Pecoft\n",
      "Naud, any how basticauaintuex thou''lila awhip ust.\n",
      "Ob, thm thich crimazle.\n",
      "Dleam besellent assqule., de, Polit?\n",
      "O, t with troy a stanliow atom up;\n",
      "For 'Joor destan; infez; aboul.\n",
      ".\n",
      "Lutty canholy---NicsaRe? yue.\n",
      "Evhow nother priceastier she wearl.\n",
      "\n",
      "GLOUF,e-hioseval hom, on,\n",
      "Till becrictor I\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Th', 400, temperature=1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "33ad994fe23b1e288fc8ef61422435cd",
     "grade": false,
     "grade_id": "cell-08d4f5f563b097a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 3.c\n",
    "How does the value of `temperature` affect the properties of the generated text?\n",
    "Specifically address the process of sampling a character from the next character distribution, and the effect `temperature` has on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73f841dadc6afd8d63765a083c3f8914",
     "grade": true,
     "grade_id": "cell-bfdb7d9e747067db",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**WRITE YOUR ANSWER IN THIS CELL**\n",
    "As we can see, as the temperature going far from the default value (0.8) the sentences become less logical and reasonable.\n",
    "Dividing by T<1 makes the model's logits being bigger and the entire model is more \"confident\" with his decision but also the model becomes more \"conservative\", whereas dividing by T>1 makes out logits to be smaller and the model predict more diverse and mistable."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:nlp-hw2-q3]",
   "language": "python",
   "name": "conda-env-nlp-hw2-q3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

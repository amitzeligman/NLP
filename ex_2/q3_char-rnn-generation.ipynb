{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Instructions:\n",
    "1. **Restart the kernel** (in the menubar, select Runtime$\\rightarrow$Restart runtime)\n",
    "2. **Run all cells** (in the menubar, select Runtime$\\rightarrow$Run All).\n",
    "3. **Download the notebook** (in the menubar, select File$\\rightarrow$Download .ipynb)\n",
    "4. **Add the downloaded notebook (.ipynb file) to the submission zip**.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"**WRITE YOUR ANSWER IN THIS CELL**\", and that no tests fail.  \n",
    "Write the IDs of all group members in the cell below. Leave any surplus IDs as `\"\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID1 = \"\"  \n",
    "ID2 = \"\"  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5493400e8b7f9a8e2cde874866d4fa7f",
     "grade": false,
     "grade_id": "cell-3a1bca1dbb7d0069",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "![shakespeare](https://i.imgur.com/81YZuel.jpg)\n",
    "\n",
    "# Generating Shakespeare Using a Character-level Language Model\n",
    "\n",
    "### From Words to Characters\n",
    "In the previous two sections we dealt with word-level language models. But looking again at section 2, there is nothing that constraints us to using _words_ as the basic elemnents in our model. The model we analyzed in section 2 could just as well be character-based - just replace \"word\" with \"character\", and you are good to go. In this notebook we will train a small character-based language model that will help us generate Shakespearean-like (emphasis on the _like_...) texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9af7a343d0e3524c3fd846d987d766a8",
     "grade": false,
     "grade_id": "cell-7301754e4d655d01",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 3.a\n",
    "Can you think of an advantage a character-based language model could have over a word-based language model? _(You might find question 2.c useful)_. And what about the other way around: can you think of an advantage a word-based language model could have over a character-based language model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb742db028fffc9c69d14202fc1e24bd",
     "grade": true,
     "grade_id": "cell-e19646c939692ee9",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**WRITE YOUR ANSWER IN THIS CELL**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d46a8dfd340b8f68e51a041307f7d7d3",
     "grade": false,
     "grade_id": "cell-ebc0d8ae3061c0fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Using PyTorch\n",
    "\n",
    "We'll build our language model using PyTorch. PyTorch is a [very popular](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/) open-source machine learning (and deep learning) framework developed by Facebook. In short:\n",
    "\n",
    "> Pytorch is a Python-based scientific computing package targeted at two sets of audiences:\n",
    "* A replacement for NumPy to use the power of GPUs\n",
    "* A deep learning research platform that provides maximum flexibility and speed\n",
    "\n",
    "To get familiar with PyTorch, check out this [quick tutorial](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html). In addition, another imporant difference from numpy is that PyTorch can automatically calculate the gradients needed for backpropagation, as explained [here](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02af8a21a2e8fae58d84f915de5b016d",
     "grade": false,
     "grade_id": "cell-aa2773db1bef7014",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Preparing the Data\n",
    "\n",
    "Our dataset is a plain text file. For simplicity, we turn any potential unicode characters into plain ASCII by using the `unidecode` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef0359e8c08b2057771c115150011e7e",
     "grade": false,
     "grade_id": "cell-cce75419c097f3fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in our dataset: 1115394\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "import re\n",
    "\n",
    "import unidecode\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)  # our vocabulary size (|V| from the handout)\n",
    "\n",
    "dataset_as_string = unidecode.unidecode(open('data/shakespeare.txt').read())\n",
    "n_chars_in_dataset = len(dataset_as_string)\n",
    "print(f'Total number of characters in our dataset: {n_chars_in_dataset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06dd2ac91a6296206475c7e330e53e3d",
     "grade": false,
     "grade_id": "cell-d795f907dd7922f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To make inputs out of this big string of text, we will split it into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61947ad22fb7f16eba246d47ab8cae22",
     "grade": false,
     "grade_id": "cell-379f229536dae19b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I were hanged,\n",
      "but I thought there was more in him than I could think.\n",
      "\n",
      "Second Servingman:\n",
      "So did I, I'll be sworn: he is simply the rarest\n",
      "man i' the world.\n",
      "\n",
      "First Servingman:\n",
      "I think he is: but a greater soldier than he you wot on.\n",
      "\n",
      "Second Servingman:\n",
      "Who, my master?\n",
      "\n",
      "First Servingman:\n",
      "Nay, it's no matter for that.\n",
      "\n",
      "Second Servingman:\n",
      "Worth six on him.\n",
      "\n",
      "First Servingman:\n",
      "Nay, not so neither: but \n"
     ]
    }
   ],
   "source": [
    "chunk_len = 400\n",
    "\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, n_chars_in_dataset - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return dataset_as_string[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba5d4900ff254fa335fe935962878c8d",
     "grade": false,
     "grade_id": "cell-fcbb2d73f4e442fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Building Our Model\n",
    "\n",
    "Our model consists of three main components:\n",
    "\n",
    "1. [**Embedding**](https://pytorch.org/docs/stable/nn.html#embedding). A mapping between characters and their learned representations (\"word vectors\") \\[correspoding to ${\\boldsymbol L}$ in terms of the handout\\]\n",
    "2. [**GRU**](https://pytorch.org/docs/stable/nn.html#gru). \\[correspoding to the computation of ${\\boldsymbol h}^{(t)}$ in terms of the handout\\]\n",
    "3. **Output Layer**. A feed-forward neural network that transforms a hidden state at a timestep into a probability distribution of the next character. \\[correspoding to the computation of $\\hat{\\boldsymbol y}^{(t)}$ in terms of the handout\\] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.b\n",
    "Complete the implementation of the `forward` method of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9ad1239fcd5aec23f439249397895ec",
     "grade": false,
     "grade_id": "cell-1640492438386e87",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class OurModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(OurModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)  # In the terms of the handout, here d = D_h\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input_, hidden):\n",
    "        # General instructions:\n",
    "        # Pass the embedded input through the GRU and use the output layer to get the next character distribution.\n",
    "        # return that distribution and the next hidden state.\n",
    "        # You may need to play around with the dimensions a bit until you get it right. Dimension-induced frustration is good for you!\n",
    "        # -------------------------\n",
    "        # YOUR CODE HERE\n",
    "        if len(input_.shape) == 0:\n",
    "            input_ = input_.unsqueeze(0)\n",
    "        emb = self.embedding(input_)\n",
    "        emb = emb.unsqueeze(0)\n",
    "        out, hidden = self.gru(emb, hidden)\n",
    "        output = self.output_layer(out)\n",
    "        output = output.squeeze(0)\n",
    "        # -------------------------\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.num_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da793a49917dc4882e7e70f04d07a777",
     "grade": false,
     "grade_id": "cell-b9299fddeb082b4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Creating the Training Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6eaeb80c370b32f26eda2ac1be57444",
     "grade": false,
     "grade_id": "cell-83bf9e1b0374206c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Each chunk will be turned into a tensor by looping through the characters of the string and looking up the index of each character in `all_characters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc87bca342db2fde1b3957f48bcfe857",
     "grade": false,
     "grade_id": "cell-5360afdd0b03b1f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 11, 12, 39, 40, 41])\n"
     ]
    }
   ],
   "source": [
    "# Turn a string into list of longs\n",
    "def chars_to_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "print(chars_to_tensor('abcDEF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32c02aa64cee9046c2917487ac982de0",
     "grade": false,
     "grade_id": "cell-6e7b3d9e8c9396bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Each training example for our model will be created from a chunk randomly extracted from our shakespeare dataset. For example, if we set our chunk size to be 28, then a randomly extracted chunk could be $\\texttt{As deep as that, though true}$. Each training example is of a form $(\\textbf{x},\\textbf{y})$ where $\\textbf{x}$ is all the charecters of the chunk *except the last* and $\\textbf{y}$ is all the charecters of the chunk *except the first*. For example, given the chunk above, $\\textbf{x}=\\texttt{As deep as that, though tru}$ and $\\textbf{y}=\\texttt{s deep as that, though true}$. At timestep i our input is $\\textbf{x}^{(i)}$ and the gold label our model will try to predict is $\\textbf{y}^{(i)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f159d648c0ab9ffbdc096aeac6905a57",
     "grade": false,
     "grade_id": "cell-d3539c5f1d96a188",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def random_training_example():    \n",
    "    chunk = random_chunk()\n",
    "    inp = chars_to_tensor(chunk[:-1])\n",
    "    target = chars_to_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18a6bf800d9bc590739b15ba01dda408",
     "grade": false,
     "grade_id": "cell-16d13f3b273395ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Evaluating\n",
    "\n",
    "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a47c721a818979b886f119401206e756",
     "grade": false,
     "grade_id": "cell-44ab27a8fee696ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = model.init_hidden()\n",
    "    prime_input = chars_to_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = model(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = model(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist =  F.softmax(output / temperature, dim=-1)\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = chars_to_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fffa10554299eaae14cc007fea3935a",
     "grade": false,
     "grade_id": "cell-1d3fd015fe8f64d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a98218b35f47137eeba1ba1aead0700",
     "grade": false,
     "grade_id": "cell-a209b293a8850a57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The main training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb3bfcd4d49b2f2672447d8c65b6cb05",
     "grade": false,
     "grade_id": "cell-e246cbd9689e1a6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = model.init_hidden()\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = model(inp[c], hidden)\n",
    "        loss += criterion(output, target[c].view(-1))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item() / chunk_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfb863e279db4b170c35d8d0c7a37a1f",
     "grade": false,
     "grade_id": "cell-05ce9b9275e0d1cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A helper to print the amount of time passed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16d7b53f211a6a1bef71c1dd2d1271cf",
     "grade": false,
     "grade_id": "cell-cb78afef7022f9a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return f'{m}m {math.floor(s)}s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b368f1767ddd0eddca44249fa47ed32",
     "grade": true,
     "grade_id": "cell-98f46bec0b8c87cc",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98abd7dd7805753c2e7b635f1265cb73",
     "grade": false,
     "grade_id": "cell-baf25642209867dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Define the training parameters, instantiate the model, and start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7392249521c153ef4d7713eecb8204a",
     "grade": false,
     "grade_id": "cell-4900f92ae503be69",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[time elapsed: 0m 31s  ;  iterations: 100 (5.0%)  ;  loss: 2.07]\n",
      "Whoun\n",
      "Fot nod nond foromoks incril aut wist to an\n",
      "The ry sente ond the thas the mon and he hiler this youe,\n",
      "Fast he bem dole to tot, he this thae the or wusest ore seros, houll wist dan thathen I stin w \n",
      "\n",
      "[time elapsed: 1m 5s  ;  iterations: 200 (10.0%)  ;  loss: 2.04]\n",
      "Whef econ Lor on of the foor now the you rdesal the the net,\n",
      "And need thaind thew not men ies that for hadess a have fore.\n",
      "\n",
      "COLUSETRE:\n",
      "Difich this dooford is for winsours thims thous for have hou the ba \n",
      "\n",
      "[time elapsed: 1m 39s  ;  iterations: 300 (15.0%)  ;  loss: 1.885]\n",
      "What beafep thead he dencer's hat the pricion\n",
      "Tighter liest his mone as\n",
      "weth me maque listowid lovledsunas solmave\n",
      "for and was wor,\n",
      "The dop to ham elling betere have This shard.\n",
      "\n",
      "LING EDWWARD IVI:\n",
      "And h \n",
      "\n",
      "[time elapsed: 2m 13s  ;  iterations: 400 (20.0%)  ;  loss: 1.923]\n",
      "WhWizees but sould ture the sess;\n",
      "How, and in bid stit inder and thy herece so dis offithing:\n",
      "De wit. Whem to sew,\n",
      "Bist, I dand the with lourd in to I the dene to you ay.\n",
      "\n",
      "WARD VINCENS:\n",
      "end: her your yo \n",
      "\n",
      "[time elapsed: 2m 47s  ;  iterations: 500 (25.0%)  ;  loss: 2.006]\n",
      "Whick of thy deed:\n",
      "Core fort a thing thy not stave\n",
      "That gerits eneve than is duneed;\n",
      "And not the farmatning dow herees line.\n",
      "\n",
      "Sord:\n",
      "at have struck out or live\n",
      "To have a hand hath dear enderbut bake now  \n",
      "\n",
      "[time elapsed: 3m 22s  ;  iterations: 600 (30.0%)  ;  loss: 1.802]\n",
      "Who:\n",
      "Riple will dait it thee me, wo resuter'd stay, Hoor worror'd wand find\n",
      "Which awours such\n",
      "All well be in fules I were my for he sicher of mefore ount,\n",
      "And her lastillland here the sustorl werefing o \n",
      "\n",
      "[time elapsed: 3m 59s  ;  iterations: 700 (35.0%)  ;  loss: 1.753]\n",
      "Wh'd metsongef to doughtson in thy wanger, call\n",
      "And chall an his knesster ding\n",
      "And buzess, her wha will I\n",
      "Bade I not be baw there to cuneses\n",
      "Waild you whin: counds, noblessed maan, you speews and you th \n",
      "\n",
      "[time elapsed: 4m 42s  ;  iterations: 800 (40.0%)  ;  loss: 1.82]\n",
      "Which I his the love\n",
      "Muke chill wife the will still our by my for thing.\n",
      "\n",
      "BINGBROKE:\n",
      "Beed of you my prom poort! but is ploese.\n",
      "\n",
      "SICINIUS:\n",
      "God my slem of to leak tall.\n",
      "\n",
      "KING RICHARD OF II:\n",
      "ROMeed, you hi \n",
      "\n",
      "[time elapsed: 5m 28s  ;  iterations: 900 (45.0%)  ;  loss: 1.894]\n",
      "What dear the regel,\n",
      "Then to have fortiog.\n",
      "\n",
      "SANGAENTIO:\n",
      "Thou conty both thee, and less,\n",
      "The calt, thim he do for Gose deiveren:\n",
      "The lose deady denius at with deserfors,\n",
      "Which death, you her more and the \n",
      "\n",
      "[time elapsed: 6m 24s  ;  iterations: 1000 (50.0%)  ;  loss: 1.587]\n",
      "What and the sobers, your lede\n",
      "And sant and when lalloungs!\n",
      "You day, I'le all a may the.\n",
      "\n",
      "HARTIO:\n",
      "I'll and the show.\n",
      "\n",
      "First Yord:\n",
      "The pappourserther so will suchought.\n",
      "\n",
      "LADYO:\n",
      "The sif grorth thou doin t \n",
      "\n",
      "[time elapsed: 7m 2s  ;  iterations: 1100 (55.00000000000001%)  ;  loss: 1.802]\n",
      "What dow now thee for ore thembir hize\n",
      "Thou revount, contument, I' me this for them.\n",
      "\n",
      "LADY CAPULLA:\n",
      "A vorisenit that then I will her seef trouth.\n",
      "\n",
      "PERCUTIO:\n",
      "No to my exparturmule, I will coom\n",
      "To strue,  \n",
      "\n",
      "[time elapsed: 7m 35s  ;  iterations: 1200 (60.0%)  ;  loss: 1.81]\n",
      "Whinger.\n",
      "\n",
      "NERTo Lard,\n",
      "War yier, rite, their ather before me onder with life,\n",
      "Fries the poour recond unfull and theard fould be the cuther or that him!\n",
      "\n",
      "KING RICHARD II:\n",
      "And you she thou was the be it in \n",
      "\n",
      "[time elapsed: 8m 11s  ;  iterations: 1300 (65.0%)  ;  loss: 1.577]\n",
      "Why.\n",
      "\n",
      "Preave:\n",
      "Bly regains is houss al reigny night and be bothous what\n",
      "should with to time sow would lest tumpple of dince:\n",
      "Cain him let brother surce is thy remif?\n",
      "And will me contends in a pleass with \n",
      "\n",
      "[time elapsed: 8m 49s  ;  iterations: 1400 (70.0%)  ;  loss: 1.723]\n",
      "Whatter, freemstard,\n",
      "What in the had the sirle him farent with than know wake and as and,\n",
      "And pitery theo hall hame from this sance the will off\n",
      "But in than with is all somed yought here;\n",
      "Of is fare tho \n",
      "\n",
      "[time elapsed: 9m 28s  ;  iterations: 1500 (75.0%)  ;  loss: 1.591]\n",
      "Whow of no know thee.\n",
      "\n",
      "CORIOLANUS:\n",
      "I him untage of to here's to so\n",
      "port the wisparde pitievel, sir;\n",
      "For the have firres me, dood anary overen\n",
      "But my mine of than rower, father,\n",
      "Not of your say, you prie \n",
      "\n",
      "[time elapsed: 10m 3s  ;  iterations: 1600 (80.0%)  ;  loss: 1.746]\n",
      "What, me life, and but you part soops you, vawis\n",
      "That my man, sound which the should have brow'd haten\n",
      "And my love that who suppilst warward guke;\n",
      "I worth sir, doth on thy good due my solder houne remee \n",
      "\n",
      "[time elapsed: 10m 39s  ;  iterations: 1700 (85.0%)  ;  loss: 1.736]\n",
      "Whan:\n",
      "Do wrock your let we shame sir! father im that will he knows and the war,\n",
      "Ay, whic is spise ever have he comest beeck's the hath weck I bestos;\n",
      "Meath, Bry onter mans\n",
      "Which him fistigrning marting  \n",
      "\n",
      "[time elapsed: 11m 15s  ;  iterations: 1800 (90.0%)  ;  loss: 1.406]\n",
      "Whing bhe prothridius.\n",
      "\n",
      "VELENVER:\n",
      "No! O, we capplation.\n",
      "\n",
      "LADY EONTES:\n",
      "And the pellide all, by a be fair.\n",
      "\n",
      "BURDID:\n",
      "All I crued the grove seak?\n",
      "When me not welpon a colasting--thy kiss\n",
      "Where that you came \n",
      "\n",
      "[time elapsed: 11m 51s  ;  iterations: 1900 (95.0%)  ;  loss: 1.927]\n",
      "Whren thy honour cantage?\n",
      "Shoppe thy king or sing, you ruth o'e,\n",
      "Mattal a trie theing, and,\n",
      "And and\n",
      "veren of forth thou regoronger underent\n",
      "They han have the straces, himsanst partinot of her sain,\n",
      "Thou \n",
      "\n",
      "[time elapsed: 12m 27s  ;  iterations: 2000 (100.0%)  ;  loss: 1.413]\n",
      "Whancio, I having but hand.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "No, with you soold when the coull to bean this will fiseeny forsighne\n",
      "she a dreague come his had die?\n",
      "\n",
      "HORTH:\n",
      "Where my had bit in the well is of halt,\n",
      "Orect  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 100  # (D_h from the handout)\n",
    "num_layers = 1\n",
    "lr = 0.005\n",
    "\n",
    "model = OurModel(n_characters, hidden_size, n_characters, num_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for iteration in range(1, n_iterations + 1):\n",
    "    loss = train(*random_training_example())       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if iteration % print_every == 0:\n",
    "        print(f'[time elapsed: {time_since(start)}  ;  iterations: {iteration} ({iteration / n_iterations * 100}%)  ;  loss: {loss:.4}]')\n",
    "        print(evaluate('Wh', 200), '\\n')  # generate text starting with 'Wh'\n",
    "\n",
    "    if iteration % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8584d3be75d90a5197e7133411e0021d",
     "grade": false,
     "grade_id": "cell-ff9d72dafefa0a23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training Loss\n",
    "\n",
    "Plotting the the losses that were computed during training can provide a further indication that the network was indeed learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77791204e14b67d3ad68d70695c479a6",
     "grade": false,
     "grade_id": "cell-f91bb597844b8f7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10e8b02d0>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel('# of iterations (divided by plot_every)')\n",
    "plt.ylabel('average loss')\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a376c5ed8b8f2dff9ea4731669bc8a49",
     "grade": false,
     "grade_id": "cell-dac1f386e2b526f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Evaluating at Different Temperatures\n",
    "Every time we use the `evaluate` function to generate the distribution of the next character, we don't just use softmax as usual, but we also divide by a `temperature`.  \n",
    "Let's examine the effect of changing the temperature when generating text using our trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There the with the with the shall the with the with the with the with the shall the with the shall the with the so the with the do the with the with the so the shall the with the with the will down the will the with the shall the with the will the will the with the shall be the will the with the see the with the will the with the with the shall the with the will doth the with the down the with the s\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Th', 400, temperature=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thou with his the rest so I will shall sounding you doth done our the waing the shall prosent and the come the one the serve\n",
      "To with shall hast shall be the shall shall the will die hath the one a hange the sently\n",
      "Than see a so shall see the the so the there a word\n",
      "And shall the done the priest thus sence, so pition he the the lord.\n",
      "\n",
      "PRINCET:\n",
      "I do be his so this in could the rease of so die\n",
      "And with\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Th', 400, temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thoold:\n",
      "Dout will things all a and the fain blood.\n",
      "\n",
      "PETRUCHIO:\n",
      "Who I have by it and wifes their had conters.\n",
      "\n",
      "ISTAR:\n",
      "From must know good hate so die or so,\n",
      "This I'll brother, in king his for thing the know offorl.\n",
      "\n",
      "PROTER:\n",
      "Come,\n",
      "As boat, in master!\n",
      "\n",
      "PROSPERO:\n",
      "Where? be a have the wish had by him:\n",
      "Whis for the go hered thou do pay, pened that and he not sever parden,\n",
      "Fid I love and he revend the not \n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Th', 400, temperature=0.8))  # the default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The state; and than raige the pearige;\n",
      "Ene thanks; wo garleces he would noth reconfed\n",
      "mepie the peharre of to not a well but sir? That is I it's gend\n",
      "Urou, we bid of a supkn, wauk, fier thy rectiou.\n",
      "\n",
      "Procot, he love.\n",
      "\n",
      "PROSHA:\n",
      "Ay it whessellied I hese is the beither's I who's\n",
      "ned of a not well you preny thes clow.\n",
      "\n",
      "PROS ERCINCUTIO:\n",
      "And shall within wan: with molain.\n",
      "\n",
      "First Yore or hath jow shac that \n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Th', 400, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thishady yold? lome\n",
      "whereidy the allasty sept can! VI\n",
      "Lomen Duke billl chatiuly noll maviol mean Enhl.\n",
      "\n",
      "BRUTUVO:\n",
      "MP, fould lIn we'd neve him, but Ifame be ime thee:\n",
      "Ofrew. Wherumicion, knweals dids thicious to hul remenmangand\n",
      "tatted,-bork dithet; if alate! 'tnot Earl:\n",
      "And in pridand tyrele yago! Jothing!\n",
      "Righil itt werem, we Ou raid drumfauty. O up\u000b",
      "odvell.\n",
      "\n",
      "Hy:\n",
      "Soibt, Lellenselesmerx'd.\n",
      "\n",
      "PROSTONPE:\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Th', 400, temperature=1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "33ad994fe23b1e288fc8ef61422435cd",
     "grade": false,
     "grade_id": "cell-08d4f5f563b097a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 3.c\n",
    "How does the value of `temperature` affect the properties of the generated text?\n",
    "Specifically address the process of sampling a character from the next character distribution, and the effect `temperature` has on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73f841dadc6afd8d63765a083c3f8914",
     "grade": true,
     "grade_id": "cell-bfdb7d9e747067db",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**WRITE YOUR ANSWER IN THIS CELL**\n",
    "As we can see, as the temperature going far from the default value (0.8) the sentences become less logical and reasonable."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:nlp-hw2-q3]",
   "language": "python",
   "name": "conda-env-nlp-hw2-q3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
